{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YJZb1q14tVAH",
        "outputId": "b87fcbef-48dd-40d8-aa35-31c2051223ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.37.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchsummary streamlit pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vdIXSlSEQuf",
        "outputId": "c5d1c47f-f3b4-4141-d545-917c18010ece",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "added 22 packages, and audited 23 packages in 2s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues, run:\n",
            "  npm audit fix\n",
            "\n",
            "Run `npm audit` for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpSf7x7YLU0P",
        "outputId": "aab172be-704b-4f8c-a926-43c252ecb7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount g drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TVtOUmp5tiun",
        "outputId": "7ad34ddf-2462-42e9-9f27-2c9a091a161c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "\"\"\"%%writefile app.py\n",
        "import torch\n",
        "from torchvision import models\n",
        "import streamlit as st\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms, utils, models\n",
        "from collections import OrderedDict\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# Set Web App title\n",
        "st.title('PNEUMONIA Image Classification')\n",
        "\n",
        "#Set Header\n",
        "st.header('Please upload the X-ray Image here: ')\n",
        "\n",
        "#Upload a file\n",
        "file=st.file_uploader('', type=['jpeg', 'jpg', 'png'])\n",
        "##load model\n",
        "# Assuming the model is saved as 'model.pth' in your Google Drive\n",
        "model_path = '/content/drive/My Drive/ZikryV3_model.pth'  # Replace with your actual path\n",
        "\n",
        "# Load the state dictionary\n",
        "state_dict = torch.load(model_path)\n",
        "\n",
        "# Determine the number of classes from the saved state dictionary\n",
        "num_classes = state_dict['fc.weight'].shape[0]  # Get the number of output features in the 'fc' layer\n",
        "\n",
        "# Create a ResNet model with the correct number of classes\n",
        "model = models.resnet18(num_classes=num_classes)  # Set num_classes\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# Now you can set the model to eval mode\n",
        "model.eval()\n",
        "\n",
        "##class Label/classname\n",
        "with open('/content/drive/My Drive/labels.txt','r') as f:\n",
        "    class_names = [a[:-1].split(' ')[1] for a in f.readlines()]\n",
        "    f.close()\n",
        "print(class_names)\n",
        "\n",
        "##Display image\n",
        "if file is not None:\n",
        "   image = Image.open(file).convert('RGB')\n",
        "   st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "\n",
        "   #classify Image\n",
        "\n",
        "\n",
        "   #write Classification\n",
        "   st.write(\"## {}\".format(class_names))\n",
        "   st.write(\"### score: {}\".format(conf_score))\n",
        "\n",
        "# Define classify function\n",
        "def classify(image, model, class_name):\n",
        "    # Convert image to (224, 224)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        conf_score = torch.nn.functional.softmax(outputs, dim=1)[0][predicted].item()\n",
        "        class_name = class_names[predicted.item()]\n",
        "\n",
        "    return class_name, conf_score\"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import torch\n",
        "from torchvision import models\n",
        "import streamlit as st\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms, utils, models\n",
        "from collections import OrderedDict\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set Web App title\n",
        "st.title('PNEUMONIA Image Classification')\n",
        "\n",
        "#Set Header\n",
        "st.header('Please upload the X-ray Image here: ')\n",
        "\n",
        "#Upload a file\n",
        "file=st.file_uploader('', type=['jpeg', 'jpg', 'png'])\n",
        "\n",
        "##load model\n",
        "# Assuming the model is saved as 'model.pth' in your Google Drive\n",
        "model_path = '/content/drive/My Drive/ZikryV3_model.pth'  # Replace with your actual path\n",
        "\n",
        "# Load the state dictionary\n",
        "state_dict = torch.load(model_path)\n",
        "\n",
        "# Determine the number of classes from the saved state dictionary\n",
        "num_classes = state_dict['fc.weight'].shape[0]  # Get the number of output features in the 'fc' layer\n",
        "\n",
        "# Create a ResNet model with the correct number of classes\n",
        "model = models.resnet18(num_classes=num_classes)  # Set num_classes\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# Now you can set the model to eval mode\n",
        "model.eval()\n",
        "\n",
        "##class Label/classname\n",
        "with open('/content/drive/My Drive/labels.txt','r') as f:\n",
        "    class_names = [a[:-1].split(' ')[1] for a in f.readlines()]\n",
        "    f.close()\n",
        "print(class_names)\n",
        "\n",
        "##Display image\n",
        "if file is not None:\n",
        "   image = Image.open(file).convert('RGB')\n",
        "   st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "\n",
        "   # Convert image to (224, 224)\n",
        "   transform = transforms.Compose([\n",
        "       transforms.Resize((224, 224)),\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "   ])\n",
        "   image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "   # Make prediction\n",
        "   model.eval()\n",
        "   with torch.no_grad():\n",
        "       outputs = model(image)\n",
        "       _, predicted = torch.max(outputs, 1)\n",
        "       conf_score = torch.nn.functional.softmax(outputs, dim=1)[0][predicted].item()\n",
        "       class_name = class_names[predicted.item()]\n",
        "\n",
        "   #write Classification\n",
        "   st.write(\"## {}\".format(class_name))\n",
        "   st.write(\"### score: {}\".format(conf_score))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HirDZSbfyYii",
        "outputId": "ec70c794-4808-4d47-f0c6-6f34c537938f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0EXcu4UkxPor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import torch\n",
        "import streamlit as st\n",
        "import os\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set Web App title\n",
        "st.title('PNEUMONIA Image Classification')\n",
        "\n",
        "# Set Header\n",
        "st.header('Please upload the X-ray Image here: ')\n",
        "\n",
        "# Upload a file\n",
        "file = st.file_uploader('', type=['jpeg', 'jpg', 'png'])\n",
        "\n",
        "# Load model\n",
        "model_path = '/content/drive/My Drive/ZikryV3_model.pth'  # Replace with your actual path\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "try:\n",
        "    model = models.resnet18(num_classes=2)  # Set num_classes\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading model: {e}\")\n",
        "\n",
        "# Load class names\n",
        "class_names = ['Normal', 'Pneumonia']  # Hardcode class names\n",
        "\n",
        "# Display image\n",
        "if file is not None:\n",
        "    image = Image.open(file).convert('RGB')\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "\n",
        "    # Define classify function\n",
        "    def classify(image, model, class_names):\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        # Make prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = model(image)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            conf_score = torch.nn.functional.softmax(outputs, dim=1)[0][predicted].item()\n",
        "            class_name = class_names[predicted.item()]\n",
        "\n",
        "        return class_name, conf_score\n",
        "\n",
        "    # Classify image\n",
        "    class_name, conf_score = classify(image, model, class_names)\n",
        "\n",
        "    # Write classification\n",
        "    st.write(\"## {}\".format(class_name))\n",
        "    st.write(\"### score: {:.2f}%\".format(conf_score * 100))\n",
        "\n",
        "    # Add confidence threshold\n",
        "    if conf_score < 0.5:\n",
        "        st.write(\"### Low confidence score. Please check the image again.\")\"\"\""
      ],
      "metadata": {
        "id": "f-HGPgzx2R1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "f0b590b5-d371-4c37-a92c-3a8e947c93b1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import torch\\nimport streamlit as st\\nimport os\\nfrom torchvision import models\\nimport torchvision.transforms as transforms\\nfrom PIL import Image\\nimport matplotlib.pyplot as plt\\n\\n# Set Web App title\\nst.title(\\'PNEUMONIA Image Classification\\')\\n\\n# Set Header\\nst.header(\\'Please upload the X-ray Image here: \\')\\n\\n# Upload a file\\nfile = st.file_uploader(\\'\\', type=[\\'jpeg\\', \\'jpg\\', \\'png\\'])\\n\\n# Load model\\nmodel_path = \\'/content/drive/My Drive/Zikry_model.pth\\'  # Replace with your actual path\\ndevice = torch.device(\\'cuda:0\\' if torch.cuda.is_available() else \\'cpu\\')\\n\\ntry:\\n    model = models.resnet18(num_classes=2)  # Set num_classes\\n    model.load_state_dict(torch.load(model_path, map_location=device))\\n    model.eval()\\nexcept Exception as e:\\n    st.error(f\"Error loading model: {e}\")\\n\\n# Load class names\\nclass_names = [\\'Normal\\', \\'Pneumonia\\']  # Hardcode class names\\n\\n# Display image\\nif file is not None:\\n    image = Image.open(file).convert(\\'RGB\\')\\n    st.image(image, caption=\\'Uploaded Image.\\', use_column_width=True)\\n\\n    # Define classify function\\n    def classify(image, model, class_names):\\n        transform = transforms.Compose([\\n            transforms.Resize((224, 224)),\\n            transforms.ToTensor(),\\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\\n        ])\\n        image = transform(image).unsqueeze(0).to(device)\\n\\n        # Make prediction\\n        with torch.no_grad():\\n            outputs = model(image)\\n            _, predicted = torch.max(outputs, 1)\\n            conf_score = torch.nn.functional.softmax(outputs, dim=1)[0][predicted].item()\\n            class_name = class_names[predicted.item()]\\n\\n        return class_name, conf_score\\n\\n    # Classify image\\n    class_name, conf_score = classify(image, model, class_names)\\n\\n    # Write classification\\n    st.write(\"## {}\".format(class_name))\\n    st.write(\"### score: {:.2f}%\".format(conf_score * 100))\\n\\n    # Add confidence threshold\\n    if conf_score < 0.5:\\n        st.write(\"### Low confidence score. Please check the image again.\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I2naCw4BKDh",
        "outputId": "bc57e4b6-a283-4845-aaa7-2774b1a4d5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.189.180.251\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Qrf_WnGLEIWm",
        "outputId": "59fa3e6a-8443-4631-8155-3247fb46af2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8504\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8504\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.189.180.251:8504\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://vast-garlics-sing.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ngrok authtoken 2kjOeavv3Irk6qSedBbkfvDqCPW_5e37YF1xEsKwGaQ2ZHmzu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5rP3PESHEp0",
        "outputId": "f1338efd-f478-4574-8974-1a590f7075f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Wait for app to start\n",
        "\"\"\"import time\n",
        "time.sleep(10)\"\"\""
      ],
      "metadata": {
        "id": "W1-Ufu1fJWQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!http 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxgZcUVyJ6qJ",
        "outputId": "2bd5af13-effd-476b-8ec1-2c202369bb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: http: command not found\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}